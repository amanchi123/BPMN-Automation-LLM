{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import subprocess\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\n",
    "The process begins when the student logs in to the university's website. He then takes an online exam. After that, the\n",
    "system grades it. If the student scores below 60%, he takes the exam again. If the student scores 60% or higher , the professor enters the grade\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tasks\": [\n",
      "    {\n",
      "      \"description\": \"logs in to the university's website\",\n",
      "      \"actor_name\": \"student\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"takes an online exam\",\n",
      "      \"actor_name\": \"student\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"grades it\",\n",
      "      \"actor_name\": \"system\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17820\\1957402152.py:52: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(json.dumps(json_output.dict(),indent=2))\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "import openai\n",
    "import json\n",
    "\n",
    "class Task(BaseModel):\n",
    "    description: str\n",
    "    actor_name: str\n",
    "\n",
    "class TaskResponse(BaseModel):\n",
    "    tasks: list[Task]\n",
    "\n",
    "def tasks(text: str) -> TaskResponse:\n",
    "    prompt = f\"\"\"\n",
    "    You're a GenAI expert in the field of banking, working on creating a BPMN workflow from text data.\n",
    "\n",
    "    Your task is to:\n",
    "    1. Read the standard operating procedure (SOP) provided to you.\n",
    "    2. Identify each task and its associated actor from the SOP.\n",
    "    3. Exclude any tasks that are conditional, involve decision points, or depend on a specific outcome (like 'if', 'then', 'otherwise', 'unless').\n",
    "\n",
    "    Extract a structured JSON list of tasks from the following text. Include only straightforward tasks that describe an action without any conditional or branching logic. Ignore any tasks or instructions that involve conditions, branching, or decisions. The output should be a plain JSON array of objects, where each object includes:\n",
    "    {{\n",
    "        \"description\": \"<Task Description>\",\n",
    "        \"actor_name\": \"<Actor>\"\n",
    "    }}\n",
    "\n",
    "    ### Instructions for Output\n",
    "    - Only include actions that are unconditional and must happen every time, with no exceptions.\n",
    "    - Exclude any tasks that depend on specific criteria or outcomes to occur.\n",
    "    - In \"description\", include only the action performed, without any reference to the actor.\n",
    "\n",
    "    Here is the SOP for you to analyze:\n",
    "\n",
    "    ***Begin SOP***\n",
    "      {text}\n",
    "    ***End SOP***\n",
    "    \"\"\"\n",
    "    response_text = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "    )['choices'][0]['message']['content'].strip()\n",
    "\n",
    "    parsed_json = json.loads(response_text)\n",
    "    if isinstance(parsed_json, list) and all(\"description\" in task and \"actor_name\" in task for task in parsed_json):\n",
    "        return TaskResponse(tasks=[Task(**task) for task in parsed_json])\n",
    "\n",
    "    return TaskResponse(tasks=[])\n",
    "\n",
    "json_output = tasks(text)\n",
    "print(json.dumps(json_output.dict(),indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tasks\": [\n",
      "    {\n",
      "      \"description\": \"Takes the exam again\",\n",
      "      \"condition\": \"Score below 60%\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"Professor enters the grade\",\n",
      "      \"condition\": \"Score 60% or higher\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17820\\2686492303.py:57: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(json.dumps(gateway_output.dict(), indent=2))\n"
     ]
    }
   ],
   "source": [
    "class Task(BaseModel):\n",
    "    description: str\n",
    "    condition: str\n",
    "\n",
    "class TaskResponse(BaseModel):\n",
    "    tasks: list[Task]\n",
    "\n",
    "def gateway(text: str) -> TaskResponse:\n",
    "    # Define the prompt for conditional tasks\n",
    "    prompt = f\"\"\"\n",
    "    You're a GenAI expert in the field of banking, working on creating a BPMN workflow from text data.\n",
    "\n",
    "    Your task is to:\n",
    "    1. Read the standard operating procedure (SOP) provided to you.\n",
    "    2. Identify each task from the SOP.\n",
    "    3. Include only tasks that are parallel, exclusive, conditional, involve decision points, or depend on a specific outcome (like 'if', 'then', 'otherwise', 'unless', 'if-else').\n",
    "\n",
    "    Extract a structured JSON list of tasks from the following text. Only include tasks that describe conditional actions, branching logic, or decisions. Ignore any tasks or instructions that happen unconditionally or must occur every time. Format the output as follows:\n",
    "    [\n",
    "        {{\n",
    "            \"description\": \"Takes the exam again\",\n",
    "            \"condition\": \"Score below 60%\"\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "    ### Instructions for Output\n",
    "    - Only include actions that are conditional, require decisions, or are based on meeting specific criteria.\n",
    "    - Do not include any straightforward tasks that occur unconditionally. Ignore any tasks that do not involve a decision or condition.\n",
    "\n",
    "    Here is the SOP for you to analyze:\n",
    "\n",
    "    ***Begin SOP***\n",
    "\n",
    "    {text}\n",
    "\n",
    "    ***End SOP***\n",
    "    \"\"\"\n",
    "\n",
    "    # Send the prompt to OpenAI's GPT model\n",
    "    response_text = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "    )['choices'][0]['message']['content'].strip()\n",
    "\n",
    "    # Parse the JSON response directly\n",
    "    parsed_json = json.loads(response_text)\n",
    "    if isinstance(parsed_json, list) and all(\"description\" in task and \"condition\" in task for task in parsed_json):\n",
    "        return TaskResponse(tasks=[Task(**task) for task in parsed_json])\n",
    "\n",
    "    # Return an empty TaskResponse if the parsed data doesn't match the expected structure\n",
    "    return TaskResponse(tasks=[])\n",
    "\n",
    "\n",
    "gateway_output = gateway(text)\n",
    "print(json.dumps(gateway_output.dict(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17820\\751442845.py:4: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  gateway_output_dict = gateway_output.dict()\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17820\\751442845.py:16: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  json_output: {json.dumps(json_output.dict())}\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17820\\751442845.py:17: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  gateway_output: {json.dumps(gateway_output.dict())}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated BPMN JSON Structure: {\n",
      "  \"BPMN\": {\n",
      "    \"startEvent\": {\n",
      "      \"id\": \"start\",\n",
      "      \"outgoing\": \"task1\"\n",
      "    },\n",
      "    \"tasks\": [\n",
      "      {\n",
      "        \"id\": \"task1\",\n",
      "        \"description\": \"logs in to the university's website\",\n",
      "        \"actor_name\": \"student\",\n",
      "        \"incoming\": \"start\",\n",
      "        \"outgoing\": \"task2\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"task2\",\n",
      "        \"description\": \"takes an online exam\",\n",
      "        \"actor_name\": \"student\",\n",
      "        \"incoming\": \"task1\",\n",
      "        \"outgoing\": \"task3\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"task3\",\n",
      "        \"description\": \"grades it\",\n",
      "        \"actor_name\": \"system\",\n",
      "        \"incoming\": \"task2\",\n",
      "        \"outgoing\": \"gateway1\"\n",
      "      }\n",
      "    ],\n",
      "    \"exclusiveGateway\": {\n",
      "      \"id\": \"gateway1\",\n",
      "      \"incoming\": \"task3\",\n",
      "      \"outgoing\": [\"task4\", \"task5\"]\n",
      "    },\n",
      "    \"conditionalTasks\": [\n",
      "      {\n",
      "        \"id\": \"task4\",\n",
      "        \"description\": \"Takes the exam again\",\n",
      "        \"condition\": \"Score below 60%\",\n",
      "        \"incoming\": \"gateway1\",\n",
      "        \"outgoing\": \"end\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"task5\",\n",
      "        \"description\": \"Professor enters the grade\",\n",
      "        \"condition\": \"Score 60% or higher\",\n",
      "        \"incoming\": \"gateway1\",\n",
      "        \"outgoing\": \"end\"\n",
      "      }\n",
      "    ],\n",
      "    \"endEvent\": {\n",
      "      \"id\": \"end\",\n",
      "      \"incoming\": [\"task4\", \"task5\"]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Integrate into BPMN workflow generation function\n",
    "\n",
    "def generate_bpmn_workflow(json_output, gateway_output):\n",
    "  gateway_output_dict = gateway_output.dict()\n",
    "  prompt = f\"\"\"\n",
    "  Given two sets of tasks in json format, 'json_output' containing straightforward tasks and 'gateway_output' containing conditional tasks, generate a structured BPMN workflow.\n",
    "\n",
    "  Your task is to:\n",
    "  - Merge both sets of tasks into a single BPMN structure.\n",
    "  - Execute the straightforward tasks in sequential order.\n",
    "  - Use an exclusive gateway to handle the conditional tasks from 'gateway_output', branching based on specified conditions.\n",
    "  - Ensure BPMN workflow includes a start event, sequential straightforward tasks, an exclusive gateway for conditional tasks, and an end event.\n",
    "  - Provide the output **only** as JSON, without any explanation or additional text, so it can be directly parsed.\n",
    "  - Exclude \"sequenceFlow\" and \"definitions\".\n",
    "\n",
    "  json_output: {json.dumps(json_output.dict())}\n",
    "  gateway_output: {json.dumps(gateway_output.dict())}\n",
    "  \"\"\"\n",
    "\n",
    "  response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a BPMN expert.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=1000,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "  return response.choices[0].message.content.strip()\n",
    "\n",
    "# Generate the BPMN structure using the generated gateway output\n",
    "bpmn_structure = generate_bpmn_workflow(json_output, gateway_output)\n",
    "print(\"Generated BPMN JSON Structure:\", bpmn_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPMN diagram saved at: BPMN_Workflow_Diagram.png\n"
     ]
    }
   ],
   "source": [
    "# Function to generate BPMN Diagram using Graphviz:\n",
    "\n",
    "def generate_bpmn_diagram(bpmn_workflow, output_filename=\"BPMN_Workflow_Diagram\"):\n",
    "    dot = Digraph('BPMN_Workflow', format='png')\n",
    "    dot.attr(rankdir='TB') \n",
    "\n",
    "    # Start Event\n",
    "    start_event = bpmn_workflow[\"workflow\"][\"start_event\"]\n",
    "    dot.node(start_event[\"id\"], \"Start\", shape=\"ellipse\", style=\"filled\", color=\"lightpink\")\n",
    "\n",
    "    # Sequential Tasks\n",
    "    previous_task_id = start_event[\"id\"]\n",
    "    for task in bpmn_workflow[\"workflow\"][\"tasks\"]:\n",
    "        task_id = task[\"id\"]\n",
    "        task_label = f\"{task['actor']}: {task['name']}\"\n",
    "        dot.node(task_id, task_label, shape=\"box\", style=\"filled\", color=\"moccasin\")\n",
    "        dot.edge(previous_task_id, task_id)\n",
    "        previous_task_id = task_id\n",
    "\n",
    "    # Exclusive Gateway\n",
    "    exclusive_gateway = bpmn_workflow[\"workflow\"][\"exclusive_gateway\"]\n",
    "    gateway_id = exclusive_gateway[\"id\"]\n",
    "    dot.node(gateway_id, \"X\", shape=\"diamond\", style=\"filled\", color=\"lightblue\")\n",
    "    dot.edge(previous_task_id, gateway_id)\n",
    "\n",
    "    # Conditional Branches\n",
    "    for branch in exclusive_gateway[\"outgoing\"]:\n",
    "        branch_id = branch[\"id\"]\n",
    "        branch_label = f\"{branch['actor']}: {branch['name']}\\nIf {branch['condition']}\"\n",
    "        dot.node(branch_id, branch_label, shape=\"box\", style=\"filled\", color=\"moccasin\")\n",
    "        dot.edge(gateway_id, branch_id, label=branch[\"condition\"])\n",
    "\n",
    "    # End Event\n",
    "    end_event = bpmn_workflow[\"workflow\"][\"end_event\"]\n",
    "    end_event_id = end_event[\"id\"]\n",
    "    dot.node(end_event_id, \"End\", shape=\"ellipse\", style=\"filled\", color=\"lightpink\")\n",
    "\n",
    "    # Connect each branch to the End Event\n",
    "    for branch in exclusive_gateway[\"outgoing\"]:\n",
    "        branch_id = branch[\"id\"]\n",
    "        dot.edge(branch_id, end_event_id)\n",
    "\n",
    "    # Save the diagram\n",
    "    output_path = f\"{output_filename}\"\n",
    "    dot.render(output_path)\n",
    "\n",
    "    # Open the image in VS Code\n",
    "    image_path = f\"{output_filename}.png\"\n",
    "    if os.name == \"nt\":\n",
    "        os.startfile(image_path) \n",
    "    else:\n",
    "        subprocess.run([\"code\", image_path]) \n",
    "\n",
    "    print(f\"BPMN diagram saved at: {image_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BPMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
